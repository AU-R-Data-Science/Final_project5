---
title: "Final_Project"
author: "Shawn Yates"
date: "2022-11-14"
output: html_document
---

```{r}
library(ggplot2)
library(dplyr)
library(caret)
library(lattice)
```

#```{r}
#data <- read.csv("~/Documents/GitHub/Final_project5/crop.data.csv")
head(data)
#```

```{r}
#sigmoid function defined as p, inverse of logit
sigmoid <- function(z){1/(1+exp(-z))} 

#objective function to be minimized
obj_fn <- function(beta, X, y){
  n <- length(y) # number of training examples

  p <- sigmoid(X%*%beta)
  J <- (t(-y)%*%log(p)-t(1-y)%*%log(1-p))/n
  J
}
```

```{r}
#gradient function
grad <- function(beta, X, y){
  n <- length(y)
  p <- sigmoid(X%*%beta)
  grad <- (t(X)%*%(p - y))/n
  grad
}
```

```{r}
beta_hat <- function(X, y){
  #remove NA rows
  temp <- na.omit(cbind(y, X))
  #add bias term and convert to matrix
  X <- mutate(temp[, -1], bias =1)
  X <- as.matrix(X[,c(ncol(X), 1:(ncol(X)-1))])
  y <- as.matrix(temp[, 1])
  #initialize beta
  beta <- matrix(rep(0, ncol(X)), nrow = ncol(X))
  #use the optim function to perform gradient descent
  obj_fnOpti <- optim(matrix(rep(0, 4), nrow = 4), obj_fn, grad, X=X, y=y)
  #return coefficients
  return(obj_fnOpti$par)
}
```
##### Training our model with our generated dataset
```{r}
set.seed(7)
n <- 20
x1 <- rpois(n, lambda = 3)
x2 <- rnorm(n, -3, 5)
x3 <- rexp(n, rate = 2)
int <- rep(1, n)
y <- c(rep(1,3), rep(0,3),rep(1,4),rep(0,3),0,1,0,1,1,0,0)
X <- cbind(x1, x2, x3)
data <- data.frame(y, X)
data.X <- data[, -1]
data.y <- data[, 1]
```

```{r}
model <- beta_hat(data.X, data.y)
model
```
The first number is the intercept. The next three numbers are the coefficient of for `x1, x2`  and  `x3`. These describe their log odds.


##### Comparing our self-built model with `glm()` function.
```{r}
true.model <- glm(y ~ x1 + x2 + x3, family=binomial(link ="logit"), data = data)
summary(true.model)$coefficients
```
##### A prediction function that will output the probability of getting 1.
```{r}
bhat.predict <- function(model, X){
  X <- na.omit(X)
  #add bias term and convert to matrix
  X <- mutate(X, bias =1)
  X <- as.matrix(X[,c(ncol(X), 1:(ncol(X)-1))])
  return(sigmoid(X%*%model))
}
```

#####  Generating a new data grid to see how `y` changes with predictors.
```{r}
set.seed(50)
n= 20
newdata <- data.frame(x1 =rpois(n,lambda = 3), x2 =runif(n,-1, 1), x3 = rexp(n, rate= 5) )

y.prediction <- bhat.predict(model, newdata)
```
```{r}
pred <- ifelse(y.prediction > 0.5, "1", "0")
```
#### Confusion matrix
```{r}

```




